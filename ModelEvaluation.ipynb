{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1E-7s3bF2FcXPyz9gF_ZG_3r3U1Mru9-1",
      "authorship_tag": "ABX9TyMCLvWEWv6LF89uGjlmZEFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tranhuuan1703/SegmentationImage/blob/main/ModelEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import libaries"
      ],
      "metadata": {
        "id": "G-LqiuW0VEvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV0kyTymVAQr",
        "outputId": "5eee15eb-0ee2-4361-bd74-ffec9c691e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m971.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=ccd1a8cb9e438437270ef9222c044e9150892daa0366270aba270200c90e5dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=6a07b96463235113236cc425684c70c363f509543e0f57d5910c9a59a0b00ab3\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "! pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#IMPORTS\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "import skimage.draw\n",
        "import tifffile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset ,DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "xTzw2sglVMWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_model_unet = \"/content/drive/MyDrive/Segmentation/your_model_u_net.pt\"\n",
        "path_model_deeplabv3 = \"/content/drive/MyDrive/Segmentation/your_model_deeplabv3.pt\""
      ],
      "metadata": {
        "id": "7-Xqjqf3VvT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229]),  # Assuming grayscale images\n",
        "    transforms.Lambda(lambda x: x.clamp(0, 1))\n",
        "])\n",
        "\n",
        "\n",
        "class CustomDataset_general(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_folder = os.path.join(root_dir, \"images\")\n",
        "        self.mask_folder = os.path.join(root_dir, \"masks\")\n",
        "        self.image_files = sorted(os.listdir(self.image_folder))\n",
        "        self.mask_files = sorted(os.listdir(self.mask_folder))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read image\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image_gray = image.convert(\"L\")  # Convert to grayscale\n",
        "\n",
        "        # Read corresponding mask\n",
        "        mask_name = self.mask_files[idx]\n",
        "        mask_path = os.path.join(self.mask_folder, mask_name)\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            # Apply transformations\n",
        "            image_gray = self.transform(image_gray)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image_gray, mask"
      ],
      "metadata": {
        "id": "xe4wBOGxV-N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj8LFbVcWl6E",
        "outputId": "f7099534-ae3f-48cd-b25a-7d1442933f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_load = torch.load(\"/content/drive/MyDrive/Segmentation/model_u_net.pt\")"
      ],
      "metadata": {
        "id": "riKwZ1R2WwxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "R7-ryGvnfXJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/MyDrive/Segmentation/segmentation_brain_data/test2\"\n",
        "dataset_test = CustomDataset_general(root_dir, transform=image_transform)\n",
        "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
        "\n",
        "iou_scores = []\n",
        "f1_scores = []\n",
        "f2_scores = []\n",
        "accuracys = []\n",
        "recalls = []\n",
        "time_loads = []\n",
        "model_load.eval()\n",
        "for batch, (X, y) in enumerate(test_loader):\n",
        "    X = X.to(DEVICE, dtype=torch.float32)\n",
        "    target = y.to(DEVICE, dtype=torch.int16)\n",
        "    start_time = time.time()\n",
        "    output = model_load(X)\n",
        "    output = (output > 0.5).float()\n",
        "    end_time = time.time()\n",
        "    tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5)\n",
        "\n",
        "    # then compute metrics with required reduction (see metric docs)\n",
        "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "    f2_score = smp.metrics.fbeta_score(tp, fp, fn, tn, beta=2, reduction=\"micro\")\n",
        "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
        "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
        "\n",
        "    iou_scores.append(iou_score.item())\n",
        "    f1_scores.append(f1_score.item())\n",
        "    f2_scores.append(f2_score.item())\n",
        "    accuracys.append(accuracy.item())\n",
        "    time_loads.append(end_time - start_time)"
      ],
      "metadata": {
        "id": "w_g8lk5EVzm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = sum(accuracys) / len(accuracys)\n",
        "iou_score = sum(iou_scores) / len(iou_scores)\n",
        "f1_score = sum(f1_scores) / len(f1_scores)\n",
        "f2_score = sum(f2_scores) / len(f2_scores)\n",
        "time_load = sum(time_loads) / len(time_loads)\n",
        "\n",
        "print(\"==================Average Metrics U-Net===================\")\n",
        "print(\"Accuracy:\",round(accuracy, 2), '%')\n",
        "print(\"IoU Score:\", round(iou_score, 2), '%')\n",
        "print(\"F1 Score:\", round(f1_score, 2), '%')\n",
        "print(\"F2 Score:\", round(f2_score, 2), '%')\n",
        "print(\"Time Load:\", round(time_load, 2), 's')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reSL9Ot_X1jv",
        "outputId": "afbfc3e9-f7c8-43a7-e6f7-e60701e5f21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Average Metrics U-Net===================\n",
            "Accuracy: 0.98 %\n",
            "IoU Score: 0.54 %\n",
            "F1 Score: 0.64 %\n",
            "F2 Score: 0.65 %\n",
            "Time Load: 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evalu model DeepLabV3"
      ],
      "metadata": {
        "id": "_Q0s1qkAdLlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Segmentation/your_model_deeplab_V3.pt\"\n",
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "\n",
        "\n",
        "ACTIVATION = None\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    in_channels=1,\n",
        "    classes=1,\n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxztO8l7dNh6",
        "outputId": "f5df7887-13df-4482-832a-8b8beafd6c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iou_scores = []\n",
        "f1_scores = []\n",
        "f2_scores = []\n",
        "accuracys = []\n",
        "recalls = []\n",
        "time_loads = []\n",
        "model_load.eval()\n",
        "for batch, (X, y) in enumerate(test_loader):\n",
        "    X = X.to(dtype=torch.float32)\n",
        "    target = y.to(dtype=torch.int16)\n",
        "    start_time = time.time()\n",
        "    output = model(X)\n",
        "    output = (output > 0.5).float()\n",
        "    end_time = time.time()\n",
        "    tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5)\n",
        "\n",
        "    # then compute metrics with required reduction (see metric docs)\n",
        "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "    f2_score = smp.metrics.fbeta_score(tp, fp, fn, tn, beta=2, reduction=\"micro\")\n",
        "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
        "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
        "\n",
        "    iou_scores.append(iou_score.item())\n",
        "    f1_scores.append(f1_score.item())\n",
        "    f2_scores.append(f2_score.item())\n",
        "    accuracys.append(accuracy.item())\n",
        "    time_loads.append(end_time - start_time)"
      ],
      "metadata": {
        "id": "0HqqIzqMbuWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = sum(accuracys) / len(accuracys)\n",
        "iou_score = sum(iou_scores) / len(iou_scores)\n",
        "f1_score = sum(f1_scores) / len(f1_scores)\n",
        "f2_score = sum(f2_scores) / len(f2_scores)\n",
        "time_load = sum(time_loads) / len(time_loads)\n",
        "print(\"==================Average Metrics DeepLabV3===================\")\n",
        "print(\"Accuracy:\",round(accuracy, 2), '%')\n",
        "print(\"IoU Score:\", round(iou_score, 2), '%')\n",
        "print(\"F1 Score:\", round(f1_score, 2), '%')\n",
        "print(\"F2 Score:\", round(f2_score, 2), '%')\n",
        "print(\"Time Load:\", round(time_load, 2), 's')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRRKCeUzcxTw",
        "outputId": "d200b47b-4ef4-4b0f-a306-6386a2cb3414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Average Metrics DeepLabV3===================\n",
            "Accuracy: 0.96 %\n",
            "IoU Score: 0.44 %\n",
            "F1 Score: 0.56 %\n",
            "F2 Score: 0.61 %\n",
            "Time Load: 0.39 s\n"
          ]
        }
      ]
    }
  ]
}